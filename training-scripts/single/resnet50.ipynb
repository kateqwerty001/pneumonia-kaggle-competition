{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-03-06T20:27:40.952239Z",
     "iopub.status.busy": "2025-03-06T20:27:40.951917Z",
     "iopub.status.idle": "2025-03-06T20:34:11.548923Z",
     "shell.execute_reply": "2025-03-06T20:34:11.547861Z",
     "shell.execute_reply.started": "2025-03-06T20:27:40.952216Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/7 - Train Loss: 0.1356 - Train AUC: 0.9881 - Val Loss: 0.1214 - Val AUC: 0.9970\n",
      "Best model saved!\n",
      "Epoch 2/7 - Train Loss: 0.0736 - Train AUC: 0.9962 - Val Loss: 0.0624 - Val AUC: 0.9971\n",
      "Best model saved!\n",
      "Epoch 3/7 - Train Loss: 0.0589 - Train AUC: 0.9978 - Val Loss: 0.1103 - Val AUC: 0.9948\n",
      "Epoch 4/7 - Train Loss: 0.0282 - Train AUC: 0.9996 - Val Loss: 0.0400 - Val AUC: 0.9990\n",
      "Best model saved!\n",
      "Epoch 5/7 - Train Loss: 0.0169 - Train AUC: 0.9999 - Val Loss: 0.0320 - Val AUC: 0.9992\n",
      "Best model saved!\n",
      "Epoch 6/7 - Train Loss: 0.0082 - Train AUC: 1.0000 - Val Loss: 0.0388 - Val AUC: 0.9990\n",
      "Epoch 7/7 - Train Loss: 0.0111 - Train AUC: 0.9997 - Val Loss: 0.0411 - Val AUC: 0.9990\n",
      "Training complete. Best Validation ROC AUC: 0.9992367975279686\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "from torch.utils.data import DataLoader, WeightedRandomSampler, random_split\n",
    "from torchvision import models\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# ==== 1. SETTING UP GPU ====\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# ==== 2. PARAMETERS ====\n",
    "data_dir = \"/kaggle/input/pneumonia/pneumonia-kaggle/train\"  # Directory containing training images\n",
    "batch_size = 32  # Number of images per batch\n",
    "epochs = 7  # Number of training epochs\n",
    "learning_rate = 1e-3  # Learning rate for the optimizer\n",
    "train_ratio = 0.8  # 80% for training, 20% for validation\n",
    "\n",
    "# ==== 3. DATA TRANSFORMATIONS ====\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  # Resize images to 224x224 pixels\n",
    "    transforms.ToTensor(),  # Convert images to PyTorch tensors\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])  # Normalize using ImageNet statistics\n",
    "])\n",
    "\n",
    "# ==== 4. LOADING DATA ====\n",
    "dataset = datasets.ImageFolder(root=data_dir, transform=transform)\n",
    "train_size = int(train_ratio * len(dataset))  # Compute training set size\n",
    "val_size = len(dataset) - train_size  # Compute validation set size\n",
    "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])  # Split dataset\n",
    "\n",
    "# Balancing class distribution in the training set\n",
    "train_labels = [dataset.targets[i] for i in train_dataset.indices]  # Get labels of training samples\n",
    "class_weights = [1 / train_labels.count(0), 1 / train_labels.count(1)]  # Compute class weights\n",
    "sample_weights = [class_weights[label] for label in train_labels]  # Assign weights to each sample\n",
    "sampler = WeightedRandomSampler(sample_weights, num_samples=len(sample_weights), replacement=True)  # Create a weighted sampler\n",
    "\n",
    "# Create DataLoaders for training and validation\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, sampler=sampler, num_workers=2, pin_memory=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=2, pin_memory=True)\n",
    "\n",
    "# ==== 5. LOADING ResNet-50 ====\n",
    "model = models.resnet50(pretrained=True)  # Load pre-trained ResNet-50 model\n",
    "model.fc = nn.Linear(model.fc.in_features, 1)  # Modify the classifier for binary classification (1 output)\n",
    "model = model.to(device)  # Move model to GPU or CPU\n",
    "\n",
    "# ==== 6. OPTIMIZER AND LOSS FUNCTION ====\n",
    "criterion = nn.BCEWithLogitsLoss()  # Binary cross-entropy loss with logits\n",
    "optimizer = optim.AdamW(model.parameters(), lr=learning_rate)  # AdamW optimizer\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=3, gamma=0.1)  # Learning rate scheduler\n",
    "\n",
    "# ==== 7. TRAINING LOOP ====\n",
    "best_auc = 0.0  # Variable to track the best validation AUC\n",
    "for epoch in range(epochs):\n",
    "    if epoch>4:\n",
    "        learning_rate = 1e-4\n",
    "    model.train()  # Set model to training mode\n",
    "    train_loss = 0.0  # Track training loss\n",
    "    all_preds, all_labels = [], []  # Store predictions and labels\n",
    "    \n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device).float().unsqueeze(1)  # Move data to GPU/CPU\n",
    "        optimizer.zero_grad()  # Zero gradients\n",
    "        outputs = model(images)  # Forward pass\n",
    "        loss = criterion(outputs, labels)  # Compute loss\n",
    "        loss.backward()  # Backpropagation\n",
    "        optimizer.step()  # Update weights\n",
    "        train_loss += loss.item()  # Accumulate loss\n",
    "        all_preds.extend(torch.sigmoid(outputs).cpu().detach().numpy())  # Store predictions\n",
    "        all_labels.extend(labels.cpu().detach().numpy())  # Store true labels\n",
    "    \n",
    "    train_auc = roc_auc_score(all_labels, all_preds)  # Compute AUC for training set\n",
    "    \n",
    "    # Validation phase\n",
    "    model.eval()  # Set model to evaluation mode\n",
    "    val_loss = 0.0  # Track validation loss\n",
    "    val_preds, val_labels = [], []  # Store validation predictions and labels\n",
    "    with torch.no_grad():  # Disable gradient calculation\n",
    "        for images, labels in val_loader:\n",
    "            images, labels = images.to(device), labels.to(device).float().unsqueeze(1)  # Move data to GPU/CPU\n",
    "            outputs = model(images)  # Forward pass\n",
    "            loss = criterion(outputs, labels)  # Compute loss\n",
    "            val_loss += loss.item()  # Accumulate loss\n",
    "            val_preds.extend(torch.sigmoid(outputs).cpu().detach().numpy())  # Store predictions\n",
    "            val_labels.extend(labels.cpu().detach().numpy())  # Store true labels\n",
    "    \n",
    "    val_auc = roc_auc_score(val_labels, val_preds)  # Compute AUC for validation set\n",
    "    print(f\"Epoch {epoch+1}/{epochs} - Train Loss: {train_loss/len(train_loader):.4f} - Train AUC: {train_auc:.4f} - Val Loss: {val_loss/len(val_loader):.4f} - Val AUC: {val_auc:.4f}\")\n",
    "    scheduler.step()  # Adjust learning rate\n",
    "    \n",
    "    # Save the best model based on validation AUC\n",
    "    if val_auc > best_auc:\n",
    "        best_auc = val_auc\n",
    "        torch.save(model.state_dict(), \"resnet50-imagenet.pth\")  # Save model weights\n",
    "        print(\"Best model saved!\")\n",
    "\n",
    "print(\"Training complete. Best Validation ROC AUC:\", best_auc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-06T20:37:24.258857Z",
     "iopub.status.busy": "2025-03-06T20:37:24.258505Z",
     "iopub.status.idle": "2025-03-06T20:37:45.537764Z",
     "shell.execute_reply": "2025-03-06T20:37:45.536802Z",
     "shell.execute_reply.started": "2025-03-06T20:37:24.258832Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-4-75b402100bfb>:8: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(\"/kaggle/working/resnet50-imagenet.pth\"))  # Load the best ResNet-50 model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submission file saved!\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import os\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "\n",
    "# ==== 8. UPLOAD THE BEST MODEL ====\n",
    "model.load_state_dict(torch.load(\"/kaggle/working/resnet50-imagenet.pth\"))  # Load the best ResNet-50 model\n",
    "model.eval()\n",
    "\n",
    "# ==== 9. CREATE SUBMISSION ====\n",
    "test_dir = \"/kaggle/input/pneumonia/pneumonia-kaggle/test\"\n",
    "test_images = sorted(os.listdir(test_dir))\n",
    "submission = []\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "for img_name in test_images:\n",
    "    img_path = os.path.join(test_dir, img_name)\n",
    "    image = Image.open(img_path).convert(\"RGB\")\n",
    "    image = transform(image).unsqueeze(0).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        output = model(image)\n",
    "        prediction = torch.sigmoid(output).item()  \n",
    "\n",
    "    submission.append([img_name, prediction])\n",
    "\n",
    "df = pd.DataFrame(submission, columns=[\"Id\", \"Category\"])\n",
    "df.to_csv(\"/kaggle/working/resnet50-imagenet.csv\", index=False)\n",
    "\n",
    "print(\"Submission file saved!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 6799205,
     "sourceId": 10934126,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30919,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
