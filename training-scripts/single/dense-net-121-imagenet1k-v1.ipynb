{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":10934126,"sourceType":"datasetVersion","datasetId":6799205}],"dockerImageVersionId":30918,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport torchvision.transforms as transforms\nimport torchvision.datasets as datasets\nfrom torch.utils.data import DataLoader, WeightedRandomSampler, random_split\nfrom torchvision import models\nfrom sklearn.metrics import roc_auc_score\n\n# ==== 1. SETTING UP GPU ====\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")\n\n# ==== 2. PARAMETERS ====\ndata_dir = \"/kaggle/input/pneumonia/pneumonia-kaggle/train\"  # Directory containing training images\nbatch_size = 32  # Number of images per batch\nepochs = 15  # Number of training epochs\nlearning_rate = 1e-4  # Learning rate for the optimizer\ntrain_ratio = 0.8  # 80% for training, 20% for validation\n\n# ==== 3. DATA TRANSFORMATIONS ====\ntransform = transforms.Compose([\n    transforms.Resize((224, 224)),  # Resize images to 224x224 pixels\n    transforms.ToTensor(),  # Convert images to PyTorch tensors\n    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])  # Normalize using ImageNet statistics\n])\n\n# ==== 4. LOADING DATA ====\ndataset = datasets.ImageFolder(root=data_dir, transform=transform)\ntrain_size = int(train_ratio * len(dataset))  # Compute training set size\nval_size = len(dataset) - train_size  # Compute validation set size\ntrain_dataset, val_dataset = random_split(dataset, [train_size, val_size])  # Split dataset\n\n# Balancing class distribution in the training set\ntrain_labels = [dataset.targets[i] for i in train_dataset.indices]  # Get labels of training samples\nclass_weights = [1 / train_labels.count(0), 1 / train_labels.count(1)]  # Compute class weights\nsample_weights = [class_weights[label] for label in train_labels]  # Assign weights to each sample\nsampler = WeightedRandomSampler(sample_weights, num_samples=len(sample_weights), replacement=True)  # Create a weighted sampler\n\n# Create DataLoaders for training and validation\ntrain_loader = DataLoader(train_dataset, batch_size=batch_size, sampler=sampler, num_workers=2, pin_memory=True)\nval_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=2, pin_memory=True)\n\n# ==== 5. LOADING (DenseNet-121) ====\nmodel = models.densenet121(weights=\"IMAGENET1K_V1\")  # Load pre-trained DenseNet-121 model\nmodel.classifier = nn.Linear(model.classifier.in_features, 1)  # Modify classifier for binary classification\nmodel = model.to(device)  # Move model to GPU or CPU\n\n# ==== 6. OPTIMIZER AND LOSS FUNCTION ====\ncriterion = nn.BCEWithLogitsLoss()  # Binary cross-entropy loss with logits\noptimizer = optim.AdamW(model.parameters(), lr=learning_rate)  # AdamW optimizer\nscheduler = optim.lr_scheduler.StepLR(optimizer, step_size=3, gamma=0.1)  # Learning rate scheduler\n\n# ==== 7. TRAINING LOOP ====\nbest_auc = 0.0  # Variable to track the best validation AUC\nfor epoch in range(epochs):\n    model.train()  # Set model to training mode\n    train_loss = 0.0  # Track training loss\n    all_preds, all_labels = [], []  # Store predictions and labels\n    \n    for images, labels in train_loader:\n        images, labels = images.to(device), labels.to(device).float().unsqueeze(1)  # Move data to GPU/CPU\n        optimizer.zero_grad()  # Zero gradients\n        outputs = model(images)  # Forward pass\n        loss = criterion(outputs, labels)  # Compute loss\n        loss.backward()  # Backpropagation\n        optimizer.step()  # Update weights\n        train_loss += loss.item()  # Accumulate loss\n        all_preds.extend(torch.sigmoid(outputs).cpu().detach().numpy())  # Store predictions\n        all_labels.extend(labels.cpu().detach().numpy())  # Store true labels\n    \n    train_auc = roc_auc_score(all_labels, all_preds)  # Compute AUC for training set\n    \n    # Validation phase\n    model.eval()  # Set model to evaluation mode\n    val_loss = 0.0  # Track validation loss\n    val_preds, val_labels = [], []  # Store validation predictions and labels\n    with torch.no_grad():  # Disable gradient calculation\n        for images, labels in val_loader:\n            images, labels = images.to(device), labels.to(device).float().unsqueeze(1)  # Move data to GPU/CPU\n            outputs = model(images)  # Forward pass\n            loss = criterion(outputs, labels)  # Compute loss\n            val_loss += loss.item()  # Accumulate loss\n            val_preds.extend(torch.sigmoid(outputs).cpu().detach().numpy())  # Store predictions\n            val_labels.extend(labels.cpu().detach().numpy())  # Store true labels\n    \n    val_auc = roc_auc_score(val_labels, val_preds)  # Compute AUC for validation set\n    print(f\"Epoch {epoch+1}/{epochs} - Train Loss: {train_loss/len(train_loader):.4f} - Train AUC: {train_auc:.4f} - Val Loss: {val_loss/len(val_loader):.4f} - Val AUC: {val_auc:.4f}\")\n    scheduler.step()  # Adjust learning rate\n    \n    # Save the best model based on validation AUC\n    if val_auc > best_auc:\n        best_auc = val_auc\n        torch.save(model.state_dict(), \"dense-net-121-imagenet1k-v1.pth\")  # Save model weights\n        print(\"Best model saved!\")\n\nprint(\"Training complete. Best Validation ROC AUC:\", best_auc)\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-03-06T18:44:27.720770Z","iopub.execute_input":"2025-03-06T18:44:27.721128Z","iopub.status.idle":"2025-03-06T18:58:41.700420Z","shell.execute_reply.started":"2025-03-06T18:44:27.721105Z","shell.execute_reply":"2025-03-06T18:58:41.699402Z"}},"outputs":[{"name":"stdout","text":"Using device: cuda\nEpoch 1/15 - Train Loss: 0.0881 - Train AUC: 0.9958 - Val Loss: 0.0384 - Val AUC: 0.9990\nBest model saved!\nEpoch 2/15 - Train Loss: 0.0217 - Train AUC: 0.9995 - Val Loss: 0.0308 - Val AUC: 0.9992\nBest model saved!\nEpoch 3/15 - Train Loss: 0.0217 - Train AUC: 0.9997 - Val Loss: 0.0394 - Val AUC: 0.9981\nEpoch 4/15 - Train Loss: 0.0104 - Train AUC: 1.0000 - Val Loss: 0.0278 - Val AUC: 0.9989\nEpoch 5/15 - Train Loss: 0.0079 - Train AUC: 1.0000 - Val Loss: 0.0226 - Val AUC: 0.9993\nBest model saved!\nEpoch 6/15 - Train Loss: 0.0069 - Train AUC: 0.9999 - Val Loss: 0.0196 - Val AUC: 0.9996\nBest model saved!\nEpoch 7/15 - Train Loss: 0.0048 - Train AUC: 1.0000 - Val Loss: 0.0194 - Val AUC: 0.9996\nBest model saved!\nEpoch 8/15 - Train Loss: 0.0035 - Train AUC: 1.0000 - Val Loss: 0.0197 - Val AUC: 0.9996\nEpoch 9/15 - Train Loss: 0.0036 - Train AUC: 1.0000 - Val Loss: 0.0200 - Val AUC: 0.9996\nEpoch 10/15 - Train Loss: 0.0043 - Train AUC: 1.0000 - Val Loss: 0.0203 - Val AUC: 0.9996\nEpoch 11/15 - Train Loss: 0.0051 - Train AUC: 1.0000 - Val Loss: 0.0200 - Val AUC: 0.9996\nEpoch 12/15 - Train Loss: 0.0044 - Train AUC: 1.0000 - Val Loss: 0.0199 - Val AUC: 0.9996\nEpoch 13/15 - Train Loss: 0.0055 - Train AUC: 1.0000 - Val Loss: 0.0203 - Val AUC: 0.9996\nEpoch 14/15 - Train Loss: 0.0034 - Train AUC: 1.0000 - Val Loss: 0.0202 - Val AUC: 0.9996\nEpoch 15/15 - Train Loss: 0.0043 - Train AUC: 1.0000 - Val Loss: 0.0199 - Val AUC: 0.9996\nTraining complete. Best Validation ROC AUC: 0.999604654340993\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"import torch\nimport os\nimport pandas as pd\nfrom PIL import Image\nfrom torchvision import transforms\n\n# ==== 8. UPLOAD THE BEST MODEL ====\nmodel.load_state_dict(torch.load(\"/kaggle/working/best_chexnet.pth\"))\nmodel.eval()\n\n# ==== 9. CREATE SUBMISSION ====\ntest_dir = \"/kaggle/input/pneumonia/pneumonia-kaggle/test\"\ntest_images = sorted(os.listdir(test_dir))\nsubmission = []\n\ntransform = transforms.Compose([\n    transforms.Resize((224, 224)),\n    transforms.ToTensor(),\n    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n])\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel.to(device)\n\nfor img_name in test_images:\n    img_path = os.path.join(test_dir, img_name)\n    image = Image.open(img_path).convert(\"RGB\")\n    image = transform(image).unsqueeze(0).to(device)\n\n    with torch.no_grad():\n        output = model(image)\n        prediction = torch.sigmoid(output).item()  # Если бинарная классификация\n\n    submission.append([img_name, prediction])\n\ndf = pd.DataFrame(submission, columns=[\"Id\", \"Category\"])\ndf.to_csv(\"/kaggle/working/submission.csv\", index=False)\n\nprint(\"Submission file saved!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-06T18:59:08.481290Z","iopub.execute_input":"2025-03-06T18:59:08.481640Z","iopub.status.idle":"2025-03-06T18:59:29.372119Z","shell.execute_reply.started":"2025-03-06T18:59:08.481599Z","shell.execute_reply":"2025-03-06T18:59:29.371304Z"}},"outputs":[{"name":"stderr","text":"<ipython-input-7-947df879cd28>:8: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  model.load_state_dict(torch.load(\"/kaggle/working/best_chexnet.pth\"))\n","output_type":"stream"},{"name":"stdout","text":"Submission file saved!\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}