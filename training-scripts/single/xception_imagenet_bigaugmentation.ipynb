{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":11031494,"sourceType":"datasetVersion","datasetId":6870539}],"dockerImageVersionId":30919,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport torchvision.transforms as transforms\nimport torchvision.datasets as datasets\nfrom torch.utils.data import DataLoader, WeightedRandomSampler, random_split\nimport timm\nfrom sklearn.metrics import roc_auc_score\n\n# ==== 1. SETTING UP GPU ====\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")\n\n# ==== 2. PARAMETERS ====\ndata_dir = \"/kaggle/input/pneumonia-merged/pneumonia-merged/train\"  # Directory containing training images\nbatch_size = 32  # Number of images per batch\nepochs = 10  # Number of training epochs\nlearning_rate = 1e-3  # Learning rate for the optimizer\ntrain_ratio = 0.8  # 80% for training, 20% for validation\n\n# ==== 3. DATA TRANSFORMATIONS ====\ntransform = transforms.Compose([\n    transforms.Resize((299, 299)),  # Xception expects 299x299 input\n    transforms.ToTensor(),  # Convert images to PyTorch tensors\n    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])  # Normalize using ImageNet statistics\n])\n\n# ==== 4. LOADING DATA ====\ndataset = datasets.ImageFolder(root=data_dir, transform=transform)\ntrain_size = int(train_ratio * len(dataset))  # Compute training set size\nval_size = len(dataset) - train_size  # Compute validation set size\ntrain_dataset, val_dataset = random_split(dataset, [train_size, val_size])  # Split dataset\n\n# Balancing class distribution in the training set\ntrain_labels = [dataset.targets[i] for i in train_dataset.indices]  # Get labels of training samples\nclass_weights = [1 / train_labels.count(0), 1 / train_labels.count(1)]  # Compute class weights\nsample_weights = [class_weights[label] for label in train_labels]  # Assign weights to each sample\nsampler = WeightedRandomSampler(sample_weights, num_samples=len(sample_weights), replacement=True)  # Create a weighted sampler\n\n# Create DataLoaders for training and validation\ntrain_loader = DataLoader(train_dataset, batch_size=batch_size, sampler=sampler, num_workers=2, pin_memory=True)\nval_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=2, pin_memory=True)\n\n# ==== 5. LOADING XCEPTION ====\nmodel = timm.create_model('xception', pretrained=True)  # Load pre-trained Xception model from timm\nmodel.fc = nn.Linear(model.fc.in_features, 1)  # Modify the classifier for binary classification (1 output)\nmodel = model.to(device)  # Move model to GPU or CPU\n\n# ==== 6. OPTIMIZER AND LOSS FUNCTION ====\ncriterion = nn.BCEWithLogitsLoss()  # Binary cross-entropy loss with logits\noptimizer = optim.AdamW(model.parameters(), lr=learning_rate)  # AdamW optimizer\nscheduler = optim.lr_scheduler.StepLR(optimizer, step_size=3, gamma=0.1)  # Learning rate scheduler\n\n# ==== 7. TRAINING LOOP ====\nbest_auc = 0.0  # Variable to track the best validation AUC\nfor epoch in range(epochs):\n    model.train()  # Set model to training mode\n    train_loss = 0.0  # Track training loss\n    all_preds, all_labels = [], []  # Store predictions and labels\n    \n    for images, labels in train_loader:\n        images, labels = images.to(device), labels.to(device).float().unsqueeze(1)  # Move data to GPU/CPU\n        optimizer.zero_grad()  # Zero gradients\n        outputs = model(images)  # Forward pass\n        loss = criterion(outputs, labels)  # Compute loss\n        loss.backward()  # Backpropagation\n        optimizer.step()  # Update weights\n        train_loss += loss.item()  # Accumulate loss\n        all_preds.extend(torch.sigmoid(outputs).cpu().detach().numpy())  # Store predictions\n        all_labels.extend(labels.cpu().detach().numpy())  # Store true labels\n    \n    train_auc = roc_auc_score(all_labels, all_preds)  # Compute AUC for training set\n    \n    # Validation phase\n    model.eval()  # Set model to evaluation mode\n    val_loss = 0.0  # Track validation loss\n    val_preds, val_labels = [], []  # Store validation predictions and labels\n    with torch.no_grad():  # Disable gradient calculation\n        for images, labels in val_loader:\n            images, labels = images.to(device), labels.to(device).float().unsqueeze(1)  # Move data to GPU/CPU\n            outputs = model(images)  # Forward pass\n            loss = criterion(outputs, labels)  # Compute loss\n            val_loss += loss.item()  # Accumulate loss\n            val_preds.extend(torch.sigmoid(outputs).cpu().detach().numpy())  # Store predictions\n            val_labels.extend(labels.cpu().detach().numpy())  # Store true labels\n    \n    val_auc = roc_auc_score(val_labels, val_preds)  # Compute AUC for validation set\n    print(f\"Epoch {epoch+1}/{epochs} - Train Loss: {train_loss/len(train_loader):.4f} - Train AUC: {train_auc:.4f} - Val Loss: {val_loss/len(val_loader):.4f} - Val AUC: {val_auc:.4f}\")\n    scheduler.step()  # Adjust learning rate\n    \n    # Save the best model based on validation AUC\n    if val_auc > best_auc:\n        best_auc = val_auc\n        torch.save(model.state_dict(), \"xception-imagenet+augmentation.pth\")  # Save model weights\n        print(\"Best model saved!\")\n\nprint(\"Training complete. Best Validation ROC AUC:\", best_auc)\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-03-14T15:02:29.930953Z","iopub.execute_input":"2025-03-14T15:02:29.931273Z","iopub.status.idle":"2025-03-14T15:43:18.249849Z","shell.execute_reply.started":"2025-03-14T15:02:29.931244Z","shell.execute_reply":"2025-03-14T15:43:18.248563Z"}},"outputs":[{"name":"stdout","text":"Using device: cuda\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/timm/models/_factory.py:117: UserWarning: Mapping deprecated model name xception to current legacy_xception.\n  model = create_fn(\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/10 - Train Loss: 0.0941 - Train AUC: 0.9943 - Val Loss: 0.0504 - Val AUC: 0.9981\nBest model saved!\nEpoch 2/10 - Train Loss: 0.0321 - Train AUC: 0.9991 - Val Loss: 0.0270 - Val AUC: 0.9995\nBest model saved!\nEpoch 3/10 - Train Loss: 0.0190 - Train AUC: 0.9996 - Val Loss: 0.0265 - Val AUC: 0.9995\nEpoch 4/10 - Train Loss: 0.0054 - Train AUC: 0.9999 - Val Loss: 0.0125 - Val AUC: 0.9999\nBest model saved!\nEpoch 5/10 - Train Loss: 0.0013 - Train AUC: 1.0000 - Val Loss: 0.0108 - Val AUC: 0.9999\nBest model saved!\nEpoch 6/10 - Train Loss: 0.0006 - Train AUC: 1.0000 - Val Loss: 0.0100 - Val AUC: 0.9999\nBest model saved!\nEpoch 7/10 - Train Loss: 0.0004 - Train AUC: 1.0000 - Val Loss: 0.0096 - Val AUC: 1.0000\nBest model saved!\nEpoch 8/10 - Train Loss: 0.0005 - Train AUC: 1.0000 - Val Loss: 0.0096 - Val AUC: 0.9999\nEpoch 9/10 - Train Loss: 0.0008 - Train AUC: 1.0000 - Val Loss: 0.0104 - Val AUC: 0.9999\nEpoch 10/10 - Train Loss: 0.0006 - Train AUC: 1.0000 - Val Loss: 0.0099 - Val AUC: 0.9999\nTraining complete. Best Validation ROC AUC: 0.9999501828515788\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"import torch\nimport os\nimport pandas as pd\nfrom PIL import Image\nfrom torchvision import transforms\nimport timm  # Import timm to use Xception\n\n# ==== 8. UPLOAD THE BEST MODEL ====\nmodel = timm.create_model('xception', pretrained=True)  # Load pre-trained Xception model from timm\nmodel.fc = torch.nn.Linear(model.fc.in_features, 1)  # Modify the final layer for binary classification (1 output)\nmodel.load_state_dict(torch.load(\"/kaggle/working/xception-imagenet+augmentation.pth\"))  # Load the best Xception model\nmodel.eval()\n\n# ==== 9. CREATE SUBMISSION ====\ntest_dir = \"/kaggle/input/pneumonia-merged/pneumonia-merged/test\"\ntest_images = sorted(os.listdir(test_dir))\nsubmission = []\n\ntransform = transforms.Compose([\n    transforms.Resize((299, 299)),  # Xception expects 299x299 input\n    transforms.ToTensor(),\n    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])  # Normalize using ImageNet statistics\n])\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel.to(device)\n\nfor img_name in test_images:\n    img_path = os.path.join(test_dir, img_name)\n    image = Image.open(img_path).convert(\"RGB\")\n    image = transform(image).unsqueeze(0).to(device)\n\n    with torch.no_grad():\n        output = model(image)\n        prediction = torch.sigmoid(output).item()  \n\n    submission.append([img_name, prediction])\n\ndf = pd.DataFrame(submission, columns=[\"Id\", \"Category\"])\ndf.to_csv(\"/kaggle/working/xception-imagenet+augmentation.csv\", index=False)\n\nprint(\"Submission file saved!\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-14T15:43:33.190366Z","iopub.execute_input":"2025-03-14T15:43:33.190708Z","iopub.status.idle":"2025-03-14T15:43:56.619716Z","shell.execute_reply.started":"2025-03-14T15:43:33.190677Z","shell.execute_reply":"2025-03-14T15:43:56.618832Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/timm/models/_factory.py:117: UserWarning: Mapping deprecated model name xception to current legacy_xception.\n  model = create_fn(\n<ipython-input-3-39ac7bb6c216>:11: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  model.load_state_dict(torch.load(\"/kaggle/working/xception-imagenet+augmentation.pth\"))  # Load the best Xception model\n","output_type":"stream"},{"name":"stdout","text":"Submission file saved!\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"df","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-14T15:51:21.263972Z","iopub.execute_input":"2025-03-14T15:51:21.264295Z","iopub.status.idle":"2025-03-14T15:51:21.273624Z","shell.execute_reply.started":"2025-03-14T15:51:21.264269Z","shell.execute_reply":"2025-03-14T15:51:21.272626Z"}},"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"             Id  Category\n0    00000.jpeg  0.729722\n1    00001.jpeg  0.999999\n2    00002.jpeg  1.000000\n3    00003.jpeg  1.000000\n4    00004.jpeg  1.000000\n..          ...       ...\n619  00619.jpeg  0.999998\n620  00620.jpeg  1.000000\n621  00621.jpeg  0.006198\n622  00622.jpeg  1.000000\n623  00623.jpeg  1.000000\n\n[624 rows x 2 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Id</th>\n      <th>Category</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>00000.jpeg</td>\n      <td>0.729722</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>00001.jpeg</td>\n      <td>0.999999</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>00002.jpeg</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>00003.jpeg</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>00004.jpeg</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>619</th>\n      <td>00619.jpeg</td>\n      <td>0.999998</td>\n    </tr>\n    <tr>\n      <th>620</th>\n      <td>00620.jpeg</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>621</th>\n      <td>00621.jpeg</td>\n      <td>0.006198</td>\n    </tr>\n    <tr>\n      <th>622</th>\n      <td>00622.jpeg</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>623</th>\n      <td>00623.jpeg</td>\n      <td>1.000000</td>\n    </tr>\n  </tbody>\n</table>\n<p>624 rows Ã— 2 columns</p>\n</div>"},"metadata":{}}],"execution_count":8}]}